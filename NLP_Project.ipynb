{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d2fa010",
   "metadata": {},
   "source": [
    "# **OBJECTIVE :** \n",
    "Detecting Spam emails Using Natural Language Processing.\\\n",
    "\"the deployment of such a model brings tangible benefits to users and organizations alike, including enhanced security, improved productivity, and a more enjoyable user experience. By minimizing the intrusion of spam messages, individuals can confidently engage with their digital platforms, while businesses can safeguard their reputation and resources\"\\\n",
    "NLP model represents a significant milestone in the advancement of artificial intelligence, with far-reaching implications for various industries and societal applications. Its remarkable capabilities not only enhance our understanding of human language but also pave the way for innovative solutions to complex linguistic challenges. As research and development in NLP continue to progress, this model serves as a beacon of excellence and inspiration for future endeavors in the field.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646130c1",
   "metadata": {},
   "source": [
    "# Step 1 :  Import Library and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0af79e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "import nltk\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(action='ignore')\n",
    "import tensorflow as tf\n",
    "import keras.models\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D , MaxPool2D ,Flatten , Dense, Dropout\n",
    "#from keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import GlobalAveragePooling2D , BatchNormalization;\n",
    "#from models import custom_convnet\n",
    "from keras.layers import Embedding,LSTM,Embedding\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "edf4c62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "spam = pd.read_csv(r\"C:\\Users\\LENOVO\\Downloads\\spam1.csv\",encoding='latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3d3d2d",
   "metadata": {},
   "source": [
    "# About Dataset\n",
    "Overview:\\\n",
    "This dataset contains a collection of emails, categorized into two classes: \"Spam\" and \"Non-Spam\" (often referred to as \"Ham\"). These emails have been carefully curated and labeled to aid in the development of spam email detection models. Whether you are interested in email filtering, natural language processing, or machine learning, this dataset can serve as a valuable resource for training and evaluation.\n",
    "\n",
    "Context:\n",
    "Spam emails continue to be a significant issue, with malicious actors attempting to deceive users with unsolicited, fraudulent, or harmful messages. This dataset is designed to facilitate research, development, and testing of algorithms and models aimed at accurately identifying and filtering spam emails, helping protect users from various threats.\n",
    "\n",
    "Content:\n",
    "The dataset includes the following features:\n",
    "Message: The content of the email, including the subject line and message body.\n",
    "Category: Categorizes each email as either \"Spam\" or \"Ham\" (Non-Spam)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "77c8b0f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e51581",
   "metadata": {},
   "source": [
    "# Step 2 : DATA PRE-PROCESSING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db5058fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam = spam.loc[:,['v1','v2']] #Dropping columns which are of no use and may affect the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db424de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Messages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6771</th>\n",
       "      <td>0</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6772</th>\n",
       "      <td>1</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6773</th>\n",
       "      <td>1</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6774</th>\n",
       "      <td>1</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6775</th>\n",
       "      <td>1</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6776 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label                                           Messages\n",
       "0         1  Go until jurong point, crazy.. Available only ...\n",
       "1         1                      Ok lar... Joking wif u oni...\n",
       "2         0  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3         1  U dun say so early hor... U c already then say...\n",
       "4         1  Nah I don't think he goes to usf, he lives aro...\n",
       "...     ...                                                ...\n",
       "6771      0  This is the 2nd time we have tried 2 contact u...\n",
       "6772      1              Will Ì_ b going to esplanade fr home?\n",
       "6773      1  Pity, * was in mood for that. So...any other s...\n",
       "6774      1  The guy did some bitching but I acted like i'd...\n",
       "6775      1                         Rofl. Its true to its name\n",
       "\n",
       "[6776 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam.rename(columns={'v1':'Label', 'v2':'Messages'}, inplace = True)\n",
    "spam.Label.replace({'ham':1, 'spam':0},inplace = True)\n",
    "spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f1957d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_x=spam.iloc[:,1]\n",
    "spam_y=spam.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1423075a",
   "metadata": {},
   "source": [
    "# Step 3: Data Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f78461c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a4f4cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(spam_x,spam_y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d47215e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=to_categorical(y_train)\n",
    "y_test=to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea413f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_num_words=10000# select 10000 words\n",
    "seq_len=50 #how many words you want to take from each doc.\n",
    "embedding_size=100 #vectoc length of each words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4888b02d",
   "metadata": {},
   "source": [
    "# Step 4: TOKENIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a36879b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer(num_words=max_num_words)\n",
    "tokenizer.fit_on_texts((spam.Messages))\n",
    "x_train=tokenizer.texts_to_sequences(x_train)# will convert the text to sequences of ID\n",
    "x_test=tokenizer.texts_to_sequences(x_test)\n",
    "x_train=pad_sequences(x_train,maxlen=seq_len)\n",
    "x_test=pad_sequences(x_test,maxlen=seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c918bbf3",
   "metadata": {},
   "source": [
    "# Step 5: Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f18ba42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Embedding(input_dim=max_num_words,\n",
    "                   input_length=seq_len,\n",
    "                   output_dim=embedding_size))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "adam=Adam(learning_rate=.001)\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cdd2c071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/14\n",
      "136/136 [==============================] - 5s 24ms/step - loss: 0.1538 - accuracy: 0.9494\n",
      "Epoch 2/14\n",
      "136/136 [==============================] - 3s 24ms/step - loss: 0.0197 - accuracy: 0.9952\n",
      "Epoch 3/14\n",
      "136/136 [==============================] - 3s 24ms/step - loss: 0.0050 - accuracy: 0.9989\n",
      "Epoch 4/14\n",
      "136/136 [==============================] - 3s 24ms/step - loss: 0.0034 - accuracy: 0.9993\n",
      "Epoch 5/14\n",
      "136/136 [==============================] - 3s 24ms/step - loss: 0.0010 - accuracy: 0.9998\n",
      "Epoch 6/14\n",
      "136/136 [==============================] - 3s 24ms/step - loss: 4.5378e-04 - accuracy: 1.0000\n",
      "Epoch 7/14\n",
      "136/136 [==============================] - 3s 24ms/step - loss: 2.1875e-04 - accuracy: 1.0000\n",
      "Epoch 8/14\n",
      "136/136 [==============================] - 3s 24ms/step - loss: 2.1279e-04 - accuracy: 1.0000\n",
      "Epoch 9/14\n",
      "136/136 [==============================] - 3s 24ms/step - loss: 9.9969e-05 - accuracy: 1.0000\n",
      "Epoch 10/14\n",
      "136/136 [==============================] - 3s 24ms/step - loss: 7.3456e-05 - accuracy: 1.0000\n",
      "Epoch 11/14\n",
      "136/136 [==============================] - 3s 24ms/step - loss: 5.8373e-05 - accuracy: 1.0000\n",
      "Epoch 12/14\n",
      "136/136 [==============================] - 3s 24ms/step - loss: 4.5121e-05 - accuracy: 1.0000\n",
      "Epoch 13/14\n",
      "136/136 [==============================] - 3s 25ms/step - loss: 3.4161e-05 - accuracy: 1.0000\n",
      "Epoch 14/14\n",
      "136/136 [==============================] - 3s 24ms/step - loss: 3.1341e-05 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1786afc4e90>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs=14,batch_size=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79f3ea6",
   "metadata": {},
   "source": [
    "# Step 6 : Predictions on Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9c9cac32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 1s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "pred=model.predict(x_test)\n",
    "pred_ma=pred.argmax(axis=1)\n",
    "y_test=y_test.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1624a7ed",
   "metadata": {},
   "source": [
    "# Step 7 : Model Performance Metrics On Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3bfa86cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 182,    7],\n",
       "       [  12, 1155]], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=confusion_matrix(y_test,pred_ma)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8cc7522c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95       189\n",
      "           1       0.99      0.99      0.99      1167\n",
      "\n",
      "    accuracy                           0.99      1356\n",
      "   macro avg       0.97      0.98      0.97      1356\n",
      "weighted avg       0.99      0.99      0.99      1356\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,pred_ma))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bd9876",
   "metadata": {},
   "source": [
    "# CONCLUSION:\n",
    "\n",
    "In conclusion, the development of an excellent NLP model for spam prediction marks a significant advancement in combating unwanted and potentially harmful messages in digital communication channels. Through meticulous data preprocessing, feature engineering, and the utilization of state-of-the-art natural language processing techniques,BI-LSTM, we have been able to achieve remarkable accuracy in identifying and filtering out spam messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4668e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
